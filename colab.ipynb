{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNSKfDgt704Z"
      },
      "source": [
        "## Molecule odor prediction via GINs with self-supervised contrastive pretraining\n",
        "*Stanford CS224W project by Sarah Chen, Matthew Ding, and Cathy Zhou*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D201UzungCX2"
      },
      "outputs": [],
      "source": [
        "# config settings \n",
        "use_pretraining = True "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Xno8Fj8Msz"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJWNTJNDe5P7",
        "outputId": "85a0159a-f7d7-4cc7-ecc0-87d54f5d88bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch has version 1.13.1\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
            "Requirement already satisfied: torch-scatter in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (2.1.0)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
            "Requirement already satisfied: torch-sparse in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (0.6.16)\n",
            "Requirement already satisfied: scipy in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from scipy->torch-sparse) (1.24.2)\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /private/var/folders/ts/5tf0q1bj7dxbchwt8wdwz2sr0000gn/T/pip-req-build-qaq7184o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /private/var/folders/ts/5tf0q1bj7dxbchwt8wdwz2sr0000gn/T/pip-req-build-qaq7184o\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 5f4a21c96e91bb4d974b7ab5f65ebabce9effd38\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: scipy in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-geometric==2.3.0) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-geometric==2.3.0) (4.65.0)\n",
            "Requirement already satisfied: jinja2 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-geometric==2.3.0) (3.1.2)\n",
            "Requirement already satisfied: requests in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-geometric==2.3.0) (2.28.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-geometric==2.3.0) (5.9.4)\n",
            "Requirement already satisfied: numpy in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-geometric==2.3.0) (1.24.2)\n",
            "Requirement already satisfied: scikit-learn in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-geometric==2.3.0) (1.2.2)\n",
            "Requirement already satisfied: pyparsing in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-geometric==2.3.0) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from jinja2->torch-geometric==2.3.0) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests->torch-geometric==2.3.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests->torch-geometric==2.3.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests->torch-geometric==2.3.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests->torch-geometric==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from scikit-learn->torch-geometric==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from scikit-learn->torch-geometric==2.3.0) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.3.0-py3-none-any.whl size=909758 sha256=93c917ddc481dd1874228cb5e6befb51a1d9bb645794f5150ea5ce859b679f92\n",
            "  Stored in directory: /private/var/folders/ts/5tf0q1bj7dxbchwt8wdwz2sr0000gn/T/pip-ephem-wheel-cache-dv0hq_d0/wheels/ba/e1/8e/28297c3201c884d3ea8c47ba71a9e71e547e556c0caa9cf5a2\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "  Attempting uninstall: torch-geometric\n",
            "    Found existing installation: torch-geometric 2.2.0\n",
            "    Uninstalling torch-geometric-2.2.0:\n",
            "      Successfully uninstalled torch-geometric-2.2.0\n",
            "Successfully installed torch-geometric-2.3.0\n",
            "Requirement already satisfied: ogb in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ogb) (1.24.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ogb) (1.26.15)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ogb) (4.65.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ogb) (1.13.1)\n",
            "Requirement already satisfied: requests in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (2.28.2)\n",
            "Requirement already satisfied: littleutils in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (67.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (3.1.0)\n",
            "Collecting pyrfume\n",
            "  Downloading pyrfume-0.18.4-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.23.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pyrfume) (1.2.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pyrfume) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.20.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pyrfume) (2.28.2)\n",
            "Collecting quantities<0.14.0,>=0.13.0\n",
            "  Downloading quantities-0.13.0.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting PubChemPy<2.0.0,>=1.0.4\n",
            "  Downloading PubChemPy-1.0.4.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting sympy>=1.6\n",
            "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "Requirement already satisfied: numpy>=1.22 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pyrfume) (1.24.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pyrfume) (1.10.1)\n",
            "Collecting plotly<6.0.0,>=5.9.0\n",
            "  Downloading plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting datajoint>0.12\n",
            "  Downloading datajoint-0.14.0-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
            "\u001b[?25hCollecting mordred<2.0.0,>=1.2.0\n",
            "  Downloading mordred-1.2.0.tar.gz (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: ipykernel>=5.5.6 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pyrfume) (6.22.0)\n",
            "Collecting toml<0.11.0,>=0.10.2\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting eden-kernel<0.4.0,>=0.3.1348\n",
            "  Downloading eden-kernel-0.3.1348.tar.gz (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.6/250.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting rdkit-pypi<2023.0.0,>=2022.3.4\n",
            "  Downloading rdkit_pypi-2022.9.5-cp38-cp38-macosx_11_0_arm64.whl (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting otumat\n",
            "  Downloading otumat-0.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting networkx<=2.6.3\n",
            "  Using cached networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "Requirement already satisfied: tqdm in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from datajoint>0.12->pyrfume) (4.65.0)\n",
            "Collecting minio>=7.0.0\n",
            "  Downloading minio-7.1.13-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from datajoint>0.12->pyrfume) (8.11.0)\n",
            "Requirement already satisfied: urllib3 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from datajoint>0.12->pyrfume) (1.26.15)\n",
            "Collecting pydot\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting pymysql>=0.7.2\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.7.1-cp38-cp38-macosx_11_0_arm64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting cryptography\n",
            "  Downloading cryptography-39.0.2-cp36-abi3-macosx_10_12_universal2.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from datajoint>0.12->pyrfume) (3.0.9)\n",
            "Collecting dill\n",
            "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "Collecting future\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: joblib in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from eden-kernel<0.4.0,>=0.3.1348->pyrfume) (1.2.0)\n",
            "Collecting toolz\n",
            "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (8.1.0)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (5.9.0)\n",
            "Requirement already satisfied: nest-asyncio in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (1.5.6)\n",
            "Requirement already satisfied: tornado>=6.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (6.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (0.1.6)\n",
            "Requirement already satisfied: packaging in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (23.0)\n",
            "Requirement already satisfied: psutil in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (5.9.4)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (5.3.0)\n",
            "Requirement already satisfied: comm>=0.1.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (0.1.3)\n",
            "Requirement already satisfied: appnope in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (0.1.3)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (1.6.6)\n",
            "Requirement already satisfied: pyzmq>=20 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipykernel>=5.5.6->pyrfume) (25.0.2)\n",
            "Requirement already satisfied: six==1.* in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from mordred<2.0.0,>=1.2.0->pyrfume) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pandas>=1.4->pyrfume) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pandas>=1.4->pyrfume) (2022.7.1)\n",
            "Collecting tenacity>=6.2.0\n",
            "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: Pillow in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from rdkit-pypi<2023.0.0,>=2022.3.4->pyrfume) (9.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests>=2.20.0->pyrfume) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests>=2.20.0->pyrfume) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from requests>=2.20.0->pyrfume) (3.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from scikit-learn>=0.23.1->pyrfume) (3.1.0)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipython->datajoint>0.12->pyrfume) (3.0.38)\n",
            "Requirement already satisfied: backcall in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipython->datajoint>0.12->pyrfume) (0.2.0)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipython->datajoint>0.12->pyrfume) (2.14.0)\n",
            "Requirement already satisfied: stack-data in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipython->datajoint>0.12->pyrfume) (0.6.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipython->datajoint>0.12->pyrfume) (0.18.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipython->datajoint>0.12->pyrfume) (4.8.0)\n",
            "Requirement already satisfied: decorator in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipython->datajoint>0.12->pyrfume) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from ipython->datajoint>0.12->pyrfume) (0.7.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=5.5.6->pyrfume) (6.1.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=5.5.6->pyrfume) (3.1.1)\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.15.1.tar.gz (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.5/508.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.39.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Using cached kiwisolver-1.4.4-cp38-cp38-macosx_11_0_arm64.whl (63 kB)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Using cached contourpy-1.0.7-cp38-cp38-macosx_11_0_arm64.whl (229 kB)\n",
            "Collecting importlib-resources>=3.2.0\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-3.0.0-cp38-cp38-macosx_11_0_arm64.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask\n",
            "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting pycparser\n",
            "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel>=5.5.6->pyrfume) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from jedi>=0.16->ipython->datajoint>0.12->pyrfume) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from pexpect>4.3->ipython->datajoint>0.12->pyrfume) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->datajoint>0.12->pyrfume) (0.2.6)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from flask->otumat->datajoint>0.12->pyrfume) (3.1.2)\n",
            "Collecting Werkzeug>=2.2.2\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting click>=8.0\n",
            "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
            "Collecting itsdangerous>=2.0\n",
            "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pure-eval in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from stack-data->ipython->datajoint>0.12->pyrfume) (0.2.2)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from stack-data->ipython->datajoint>0.12->pyrfume) (2.2.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from stack-data->ipython->datajoint>0.12->pyrfume) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from Jinja2>=3.0->flask->otumat->datajoint>0.12->pyrfume) (2.1.2)\n",
            "Building wheels for collected packages: eden-kernel, mordred, PubChemPy, quantities, future, cffi\n",
            "  Building wheel for eden-kernel (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for eden-kernel: filename=eden_kernel-0.3.1348-py3-none-any.whl size=48708 sha256=934da428d7d2ca7b412230a4b665571a09f465f10aa6310d248c2df62a3a0a4a\n",
            "  Stored in directory: /Users/cathyzhou/Library/Caches/pip/wheels/fe/66/89/74d9147708e247bb67c29c84df1ae8c34a56f9b70b13b2f31c\n",
            "  Building wheel for mordred (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for mordred: filename=mordred-1.2.0-py3-none-any.whl size=176720 sha256=02df16335af082e57efc22dd1f8c8fbc4122ba3d272714da03cd3148f73e5b5a\n",
            "  Stored in directory: /Users/cathyzhou/Library/Caches/pip/wheels/20/88/41/5d873c9b55dc7479f0b9951c2161d7b09be193e7228ea27309\n",
            "  Building wheel for PubChemPy (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for PubChemPy: filename=PubChemPy-1.0.4-py3-none-any.whl size=13819 sha256=d9a294bfb6523aaeaa89d34a55ba8779b207d804cfe69a6d2fb1cd68ee1b096e\n",
            "  Stored in directory: /Users/cathyzhou/Library/Caches/pip/wheels/b0/8c/ba/3b00b89931153bf5a4eaa8e73bd1b0319a879cc45175326854\n",
            "  Building wheel for quantities (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for quantities: filename=quantities-0.13.0-py3-none-any.whl size=77858 sha256=deb0ec60bc8ee937dc2ad7cf889822c83d7dfff25d0bd2b2c353ac3697b71678\n",
            "  Stored in directory: /Users/cathyzhou/Library/Caches/pip/wheels/a2/54/36/12af6e58a292a912f4bcd62d146d593fadcd414a258a970cf2\n",
            "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=dbc0de5f65df365851db953c7ffe0b0e27d007681faf92b8a68ff02ae0da3fa9\n",
            "  Stored in directory: /Users/cathyzhou/Library/Caches/pip/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11\n",
            "  Building wheel for cffi (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for cffi: filename=cffi-1.15.1-cp38-cp38-macosx_11_0_arm64.whl size=169049 sha256=e690b6185912e2af5bf15429ce944e37ba96082ea828fa7c37b26cff380de1a2\n",
            "  Stored in directory: /Users/cathyzhou/Library/Caches/pip/wheels/4f/6c/1c/87e97bb9c55afbf66881d37eed21c108b012c29105af6be450\n",
            "Successfully built eden-kernel mordred PubChemPy quantities future cffi\n",
            "Installing collected packages: quantities, PubChemPy, mpmath, appdirs, Werkzeug, watchdog, toolz, toml, tenacity, sympy, rdkit-pypi, pymysql, pydot, pycparser, networkx, minio, kiwisolver, itsdangerous, importlib-resources, future, fonttools, dill, cycler, contourpy, click, plotly, mordred, matplotlib, flask, cffi, eden-kernel, cryptography, otumat, datajoint, pyrfume\n",
            "Successfully installed PubChemPy-1.0.4 Werkzeug-2.2.3 appdirs-1.4.4 cffi-1.15.1 click-8.1.3 contourpy-1.0.7 cryptography-39.0.2 cycler-0.11.0 datajoint-0.14.0 dill-0.3.6 eden-kernel-0.3.1348 flask-2.2.3 fonttools-4.39.2 future-0.18.3 importlib-resources-5.12.0 itsdangerous-2.1.2 kiwisolver-1.4.4 matplotlib-3.7.1 minio-7.1.13 mordred-1.2.0 mpmath-1.3.0 networkx-2.6.3 otumat-0.3.1 plotly-5.13.1 pycparser-2.21 pydot-1.4.2 pymysql-1.0.2 pyrfume-0.18.4 quantities-0.13.0 rdkit-pypi-2022.9.5 sympy-1.11.1 tenacity-8.2.2 toml-0.10.2 toolz-0.12.0 watchdog-3.0.0\n",
            "Cloning into 'GraphSSL'...\n",
            "remote: Enumerating objects: 187, done.\u001b[K\n",
            "remote: Total 187 (delta 0), reused 0 (delta 0), pack-reused 187\u001b[K\n",
            "Receiving objects: 100% (187/187), 54.62 KiB | 787.00 KiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n",
            "Collecting torch-ema\n",
            "  Downloading torch_ema-0.3-py3-none-any.whl (5.5 kB)\n",
            "Requirement already satisfied: torch in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch-ema) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/cathyzhou/miniforge3/envs/graph/lib/python3.8/site-packages (from torch->torch-ema) (4.5.0)\n",
            "Installing collected packages: torch-ema\n",
            "Successfully installed torch-ema-0.3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))\n",
        "\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install ogb\n",
        "!pip install pyrfume\n",
        "!git clone https://github.com/paridhimaheshwari2708/GraphSSL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KbhzxZzYe9h9",
        "outputId": "be13bbe4-28ee-4361-8a3f-6e9e66db2b45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LpAD2TOxe-6t"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch_geometric.seed.seed_everything(0)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1K5eY9yfCne",
        "outputId": "accd3dd3-b476-4ec6-994d-ab716caaeee3"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# TODO: for now mount drive, but replace this with GitHub repo and %cd soon! \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m, force_remount\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m FOLDERNAME \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCS224W\u001b[39m\u001b[39m'\u001b[39m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# TODO: for now mount drive, but replace this with GitHub repo and %cd soon! \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "FOLDERNAME = 'CS224W'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CS224W/GNNose/src')\n",
        "sys.path.append(\"/content/GraphSSL/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxGO2M718QfJ"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jh4Aa-kxfK2R"
      },
      "outputs": [],
      "source": [
        "# load and split the dataset \n",
        "from odor_data import get_graph_data\n",
        "\n",
        "graph_list = get_graph_data('lw')\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(graph_list, [0.7, 0.1, 0.2])\n",
        "\n",
        "batch_size = 256 # TODO\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, drop_last=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssHoeZgW8WNA"
      },
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q3V2W4U0gv5N"
      },
      "outputs": [],
      "source": [
        "# set hyperparameters\n",
        "in_channels = list(graph_list[2].x.shape)[-1]\n",
        "out_channels = 1 # list(graph_list[2].y.shape)[1]\n",
        "# TODO\n",
        "hidden_channels = 64\n",
        "num_layers = 1\n",
        "dropout_p = 0.5\n",
        "pooling_type = 'max'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1G1vGbMJg8T0"
      },
      "outputs": [],
      "source": [
        "# initialize model \n",
        "from odor_model import ScentClassifier\n",
        "\n",
        "model = ScentClassifier(\n",
        "    in_channels,\n",
        "    hidden_channels, \n",
        "    num_layers, \n",
        "    out_channels,\n",
        "    dropout=dropout_p,\n",
        "    pooling_type=pooling_type,\n",
        ")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9DNWRz98XVD"
      },
      "source": [
        "### Apply pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lYC4ejMVfW7k",
        "outputId": "9f36d56b-17ca-42ad-9481-d58099c3622a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# samples in train subset: 2466\n",
            "# samples in val subset: 352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/120 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m val_losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(pretrain_epochs)):\n\u001b[0;32m---> 26\u001b[0m     train_loss \u001b[39m=\u001b[39m pretrain(pretrain_model, pretrain_optimizer, epoch, \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, pretrain_train_loader, device)\n\u001b[1;32m     27\u001b[0m     val_loss \u001b[39m=\u001b[39m pretrain(pretrain_model, pretrain_optimizer, epoch, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, pretrain_val_loader, device)\n\u001b[1;32m     28\u001b[0m     log \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m, Val Loss: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
            "File \u001b[0;32m~/Documents/Workspace/cs224w-project/GNNose/odor_pretrain.py:34\u001b[0m, in \u001b[0;36mpretrain\u001b[0;34m(model, optimizer, epoch, mode, dataloader, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m \u001b[39m# readout_anchor is the embedding of the original datapoint x on passing through the model\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m readout_anchor \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx_anchor, \n\u001b[1;32m     35\u001b[0m             data\u001b[39m.\u001b[39;49medge_index_anchor, data\u001b[39m.\u001b[39;49mx_anchor_batch) \u001b[39m# removed wrapping tup\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# readout_positive is the embedding of the positively augmented x on passing through the model\u001b[39;00m\n\u001b[1;32m     38\u001b[0m readout_positive \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx_pos, \n\u001b[1;32m     39\u001b[0m             data\u001b[39m.\u001b[39medge_index_pos, data\u001b[39m.\u001b[39mx_pos_batch) \u001b[39m# removed wrapping tup\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/graph/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Documents/Workspace/cs224w-project/GNNose/odor_model.py:64\u001b[0m, in \u001b[0;36mPretrainingGIN.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index, batch\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m])):\n\u001b[0;32m---> 64\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     65\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgnn(x, edge_index)\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(h, batch)\n",
            "File \u001b[0;32m~/miniforge3/envs/graph/lib/python3.8/site-packages/torch/cuda/__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "# apply pretraining \n",
        "if use_pretraining:\n",
        "    from odor_pretrain import build_pretraining_loader, pretrain\n",
        "    from odor_model import PretrainingGIN\n",
        "    \n",
        "    pretrain_epochs = 120\n",
        "    pretrain_batch_size = 256\n",
        "    pretrain_lr = 1e-4\n",
        "    pretrain_weight_decay = 1e-5\n",
        "\n",
        "    pretrain_train_loader = build_pretraining_loader(train_set, \"train\", batch_size=batch_size)\n",
        "    pretrain_val_loader = build_pretraining_loader(val_set, \"val\", batch_size=batch_size)\n",
        "\n",
        "    pretrain_model = PretrainingGIN(\n",
        "        in_channels, \n",
        "        hidden_channels, \n",
        "        num_layers, \n",
        "        out_channels,\n",
        "        dropout=dropout_p\n",
        "    ).to(device)\n",
        "\n",
        "    pretrain_optimizer = torch.optim.Adam(pretrain_model.parameters(), lr=pretrain_lr, weight_decay=pretrain_weight_decay)\n",
        "\n",
        "    val_losses = []\n",
        "    for epoch in tqdm(range(pretrain_epochs)):\n",
        "        train_loss = pretrain(pretrain_model, pretrain_optimizer, epoch, \"train\", pretrain_train_loader, device)\n",
        "        val_loss = pretrain(pretrain_model, pretrain_optimizer, epoch, \"val\", pretrain_val_loader, device)\n",
        "        log = \"Epoch {}, Train Loss: {:.3f}, Val Loss: {:.3f}\"\n",
        "        print(log.format(epoch, train_loss, val_loss))\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "    plt.plot(range(len(val_losses)), val_losses)\n",
        "    plt.title(f\"../pretraining/best_{epoch}_{hidden_channels}_{num_layers}_{batch_size}_{dropout_p}_{pretrain_lr}_{pretrain_weight_decay}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    model.gnn.load_state_dict(\n",
        "        pretrain_model.gnn.state_dict()\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e66m8PYO8ZNY"
      },
      "source": [
        "### Finetune on labeled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-1QBlycdhBm9",
        "outputId": "be6ab9d7-321a-4564-af04-e8263c7a5ecb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/60 [00:00<00:19,  3.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss 0.040288806831749686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 2/60 [00:00<00:18,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss 0.03828838213806895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 3/60 [00:00<00:17,  3.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss 0.03811069010528045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 4/60 [00:01<00:17,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss 0.03704132264161245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 5/60 [00:01<00:17,  3.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss 0.036224382057097125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 6/60 [00:01<00:17,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss 0.035225715660410786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 7/60 [00:02<00:17,  3.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss 0.034818799923032835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 8/60 [00:02<00:16,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss 0.03383284841044009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 9/60 [00:02<00:16,  3.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss 0.03265778494383974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 10/60 [00:03<00:15,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss 0.032731414518023735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 11/60 [00:03<00:17,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss 0.03191575072010842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 12/60 [00:04<00:19,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Loss 0.03290212241402508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 13/60 [00:04<00:20,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Loss 0.032905578226552004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 14/60 [00:05<00:20,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Loss 0.031512641752046586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 15/60 [00:05<00:20,  2.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Loss 0.03216334773772921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 16/60 [00:06<00:20,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Loss 0.032883250220268605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 17/60 [00:06<00:20,  2.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Loss 0.03150273394217263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 18/60 [00:07<00:20,  2.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Loss 0.032319883167115246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 19/60 [00:07<00:20,  2.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Loss 0.03237776396628424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 20/60 [00:08<00:20,  2.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Loss 0.030575950457038478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 21/60 [00:08<00:19,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Loss 0.03139047108330769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 22/60 [00:09<00:18,  2.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, Loss 0.030722691194854514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 23/60 [00:09<00:16,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22, Loss 0.030199620362132522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 24/60 [00:09<00:14,  2.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23, Loss 0.029816347510468542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 25/60 [00:10<00:13,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24, Loss 0.03022476665778365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 26/60 [00:10<00:12,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25, Loss 0.03070705225094488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 27/60 [00:10<00:11,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26, Loss 0.029132103011169187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 28/60 [00:11<00:10,  3.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27, Loss 0.030694221348078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 29/60 [00:11<00:10,  3.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28, Loss 0.02967771493798818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 30/60 [00:11<00:09,  3.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29, Loss 0.027252843876921444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 31/60 [00:11<00:09,  3.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30, Loss 0.027976212420312736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 32/60 [00:12<00:09,  3.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31, Loss 0.028980595448688095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 33/60 [00:12<00:08,  3.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32, Loss 0.02960826319983019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 34/60 [00:12<00:08,  3.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33, Loss 0.029210466344667854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 35/60 [00:13<00:08,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34, Loss 0.029654765651173837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 36/60 [00:13<00:07,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35, Loss 0.03146947252005943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 37/60 [00:13<00:07,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36, Loss 0.030946196720837968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 38/60 [00:14<00:07,  3.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37, Loss 0.030736780321317676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 39/60 [00:14<00:06,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38, Loss 0.028516458672231904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 40/60 [00:14<00:06,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39, Loss 0.030077616180333295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 41/60 [00:15<00:06,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40, Loss 0.032451267660099224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 42/60 [00:15<00:05,  3.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41, Loss 0.030212314169482304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 43/60 [00:15<00:05,  3.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42, Loss 0.029013003746088405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 44/60 [00:16<00:04,  3.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43, Loss 0.028492747528806317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 45/60 [00:16<00:04,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44, Loss 0.027910369059368546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 46/60 [00:16<00:04,  3.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45, Loss 0.026984715790450815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 47/60 [00:17<00:04,  3.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46, Loss 0.028185559788662926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 48/60 [00:17<00:03,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47, Loss 0.026130030625057917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 49/60 [00:17<00:03,  3.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48, Loss 0.027727484799746276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 50/60 [00:17<00:03,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49, Loss 0.028013067910657698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 51/60 [00:18<00:02,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50, Loss 0.027180813621527185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 52/60 [00:18<00:02,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51, Loss 0.028597001031657496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 53/60 [00:18<00:02,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52, Loss 0.02828940703244298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 54/60 [00:19<00:01,  3.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53, Loss 0.029977961274925906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 55/60 [00:19<00:01,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54, Loss 0.030710628529631405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 56/60 [00:20<00:01,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55, Loss 0.02991280629203654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 57/60 [00:20<00:01,  2.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56, Loss 0.029308394117270268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 58/60 [00:21<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57, Loss 0.028268388491380726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 59/60 [00:21<00:00,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58, Loss 0.02794422372414248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [00:22<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59, Loss 0.026547945715601814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x200 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# train the model \n",
        "from odor_train import train, test\n",
        "from torch_ema import ExponentialMovingAverage\n",
        "\n",
        "num_epochs = 60\n",
        "lr = 0.001\n",
        "weight_decay = 1e-5\n",
        "\n",
        "roc_scores, f1_scores, accs, losses = [], [], [], []\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "ema = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
        "\n",
        "\n",
        "roc_scores = []\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    loss = train(model, optimizer, train_loader, device, weighted_BCE=True)\n",
        "    train_acc, train_preds, train_true  = test(model, train_loader, device)\n",
        "    test_acc, test_preds, test_true = test(model, test_loader, device)\n",
        "    # log(Epoch=epoch, Loss=loss, Train=train_acc, Test=test_acc)\n",
        "    log = \"Epoch {}, Loss {}\"\n",
        "    print(log.format(epoch, loss))\n",
        "\n",
        "\n",
        "    # bootrapped ROC AUC score over entire test set\n",
        "    _, whole_test_preds, whole_test_true = test(\n",
        "        model, DataLoader(test_set, batch_size=len(test_set), shuffle=True), device)\n",
        "    whole_test_preds = whole_test_preds.squeeze()\n",
        "    whole_test_true = whole_test_true.squeeze()\n",
        "    rocauc_score = roc_auc_score(whole_test_true.cpu(), whole_test_preds.cpu())\n",
        "    f1 = f1_score(whole_test_true.cpu(), whole_test_preds.cpu())\n",
        "\n",
        "    roc_scores.append(rocauc_score)\n",
        "    f1_scores.append(f1)\n",
        "    accs.append(accuracy_score(whole_test_true.cpu(), whole_test_preds.cpu()))\n",
        "    losses.append(loss)\n",
        "\n",
        "fig, ax = plt.subplots(1, 4, figsize=(6, 2))\n",
        "for i, (name, metric) in enumerate([\n",
        "    ('loss', losses), ('acc', accs), ('f1', f1_scores), ('roc', roc_scores)\n",
        "]):\n",
        "    ax[i].plot(range(len(metric)), metric)\n",
        "    ax[i].set_ylim((0, 1))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
